# Thread Basic

## 개요

SMP<sup id = "a1">[1](#f1)</sup>와 같은 shared memory multiprocessor architectures에서 **thread는 병렬화를 달성하기 위해서 사용된다.** 스레드 구현은 하드웨어 벤더에서 그들 자신의 필요에 의해서 만들어서 사용했으며 후에 소프트웨어 개발자들이 간단하게 사용할 수 있도록 작성하게 되었다. UNIX에서는 C 언어를 위한 표준 thread 프로그래밍 인터페이스를 사용하는데, IEEE POSIX 1003.1c 에 그 표준이 정의되어 있다. 이를 **POSIX Thread** 라고 부르게 되었고, 더욱 줄여서 **pthread** 라고 부르고 있다.

- **병행 프로그래밍** : `Concurrent` Programming

  - 실제로는 하나만 실행되고 있을 수 있지만 시간을 쪼개어 빠르게 돌면 동시에 실행되는 것처럼 보인다.

  - 프로그램의 성질

- **병렬 프로그래밍** : `Parallel` Programming

  - 기계(하드웨어)의 성질 (하드웨어적인 서포트가 필요)

  - `OpenMP, MPI, CUDA` 와 같은 프로그래밍 방법론은 병행보다 *병렬 프로그래밍이 옳은 표현* 이다. 모두 물리적으로 제공되는 다양한 병렬 하드웨어의 성질이기 때문.

## 스레드는 무엇이며, 왜 이용하는가

스레드는 `세미 프로세스(Semi Process)`, 혹은 `Light Weight Process(LWP)` 라고 불리며, 여러 개의 클라이언트를 처리하는 서버/클라이언트 모델의 서버 프로그래밍 작업을 위해서 주로 사용된다. 
  
  - 비슷한 일을 하는 `fork()`에 비해서 빠른 프로세스 생성 능력과, 적은 메모리를 사용하는게 LWP라고 불리우는 이유이다.

보통의 유닉스 프로세스는 main() 함수에 의해서 시작되고 실행되는 single 쓰레드로 이루어지며, 하나의 연속된 명령어들만을 처리한다. 반면 멀티스레드 프로그램은 여러 개의 연속된 명령어들을 동시에 처리할수 있다.

스레드는 자기 자신의 스택 메모리 영역을 가지고, 코드의 조각을 실행한다. 실(real) 프로세스 와는 달리 **스레드는 다른 형제 스레드들과 메모리를 공유**하게 된다. (보통 프로세스는 자기자신만의 메모리영역을 가진다).

  - 이렇듯 전역 메모리를 공유하게 되므로 **fork 방식에 비해서 좀더 작은 메모리를 소비**하게 된다. ([**TLS**](https://github.com/june0122/TIL/blob/master/JAVA/TLS.md)를 통해 스레드 별로 고유한 저장공간을 가질 수 있다.)

fork 에 비해서 thread 가 가지는 장점은 위에서 언급했듯이 "빠른 프로세스 생성" 능력과, 메모리 공유를 위한 "적은 메모리의 사용"과 메모리 공유에 따른 스레드 간의 좀 더 쉬운 정보 공유이다.

  - fork() 시스템에서 부모와 자식같이 통신을 위해서는 IPC를 사용해야 하며 이는 꽤 어려운 작업이 될수도 있는데, 메모리를 공유함으로 **IPC**(Inter-Process Communication, 프로세스간 통신)의 사용을 줄이면서도 스레드간 정보교환을 쉽게 할 수 있다.

> `fork()`를 이용한 프로세스 생성과 `pthread_create()`를 이용한 thread 생성 간의 비용을 비교한 표

<p align = "center">
<img src = "https://user-images.githubusercontent.com/39554623/56563871-c6e11000-65e7-11e9-9daf-3229481ed514.PNG" width = "100%">
</p>

fork에 비해서 스레드가 더 빠른 수행능력을 보이는 이유는 **fork**가 기본적으로 모든 메모리와 모든 기술자(파일 기술자등)을 **copy-on-write 방식**으로 자식에게 복사하는데 비해서 **스레드는 많은 부분을 공유**하기 때문이다. copy-on-write 자체가 효율적이긴 하지만, 메모리 자원을 공유하는 것보다는 느릴 수 밖에 없다.

반면 **스레드의 단점**으로는, **모든 스레드가 같은 메모리 공간을 공유하게 되므로, 하나의 쓰레드가 잘못된 메모리 연산을 하게 되면, 모든 프로세스가 그 영향을 받게 된다는 것**이다.

  - **fork** 등을 통한 프로세스 생성 방식에 있어서는 **OS가 각각의 프로세스를 보호해줌**으로 한 프로세스의 문제는 해당 프로세스의 문제로 끝나게 된다.
  
  - 그러나 스레드는 이러한 프로세스 보호를 기대할수 없다. 하나의 스레드에 문제가 생기면 전체 스레드에 문제가 생길 가능성이 크다. 
  
  - 이런 이유로 멀티 스레드 프로그램은 좀 더 주의를 기울여서 작성해야 한다. 또 단 하나의 흐름을 가지는 단일 프로세스 프로그램과 달리, 여러개의 흐름으로 분리가 되기 때문에, 디버깅을 하기가 까다롭다는 문제도 가진다.

### 개념 정리

> **Thread**
 
**운영체제에서 스케쥴링<sup id = "a2">[2 ](#f2)</sup>이 가능한 독립된 명령(instructions) 흐름 단위**이다. 여기에서 독립된 명령 단위를 보통 **문맥**이라고 표기한다. 스케쥴링 가능한 문맥 혹은 코드조각으로 이해하면 될 것 같다.

- **★ 운영체제의 목적 : 자원의 관리 !!**









---

## <b id = "f1"><sup>1</sup></b> SMP (Symmetric Multiprocessing)[ `↩`](#a1)

`대칭형 다중 처리`(symmetric multiprocessing, SMP)는 **두 개 또는 그 이상의 프로세서가 한 개의 공유된 메모리를 사용하는 다중 프로세서 컴퓨터 아키텍처**이다. 현재 사용되는 대부분의 다중 프로세서 시스템은 SMP 아키텍처를 따르고 있다.

<br>
<p align = "center">
<img src = "https://user-images.githubusercontent.com/39554623/56559288-220d0580-65dc-11e9-870d-5bfb9d912c92.png" width = "70%">
</p>


## <b id = "f2"><sup>2</sup></b> 스케쥴링 (Scheduling)[ `↩`](#a2)

### 프로세스 스케쥴러란?

- 다음 번에 실행될 프로세스를 선택하는 커널 컴포넌트.

- 시스템에 있는 실행 가능한 프로세스들에게 **유한한 프로세서 시간을 분배**해 주는 커널의 하위 시스템

- 리눅스와 같은 멀티태스킹 운영체제의 기본요소로 어느 프로세스를 실행할 것인가를 선택하는 동시에, 시스템의 성능을 최적화하고, **여러 개의 프로세스가 *마치 동시에 실행되고 있는 것과 같이 보이도록* 해야 하는 책임을 갖는다.**

- 동작시나리오

  - 실행가능한 프로세스가 여럿 있다고 할 때 프로세서(CPU)를 최대한 이용하기 위해서는 **항상 어떤 프로세스든 실행 중**이면 되는 것이다. 만약 시스템의 프로세서 수보다 많은 프로세스가 있을 경우 몇몇 프로세스는 실행될 수 없다. 이러한 프로세스들을 실행하기 위해 대기중이라는 상태가 있다.

- **여러 프로세스 중에서 다음 프로세스를 선택하는 것**이 **스케쥴러가 행하는 가장 중요한 작업**이다.

### 선점형, 비선점형 스케쥴링

현재 특정 작업이 CPU를 선점하고 있을 때, 우선 순위가 높은 작업이 오면 CPU에 대한 점유를 뺏어올 수 있냐 없느냐에 따라 구분할 수 있다.

> **비선점형 스케줄링(Non-preemptive Scheduling)**

- 특정 프로세스가 CPU 를 **독점하는 것이 가능** (프로세스가 스스로 CPU 점유를 포기해야만 다른 프로세스가 실행)

  - 프로세스가 자발적으로 실행을 중단할 때까지 중단되지 않는다. 자발적으로 자신을 중단시키는 일을 `양보(yield)`라 한다.

> **선점형 스케줄링(Preemptive Scheduling)**

- 특정 프로세스가 CPU 를 **독점하는 것이 불가능** (운영체제가 강제로 프로세스의 CPU 점유를 제어)

  - **리눅스는** 윈도우와 같은 다른 최신 운영체제들과 마찬가지로 **선점형 멀티태스킹**을 지원한다.

  - 선점형 멀티태스킹은 프로세스가 언제 실행을 중지하고 또는 실행을 계속할 것인가를 바로 스케줄러가 결정.

### 'I/O' 중심 프로세스, '프로세서' 중심 프로세스

- **I/O 중심 프로세스**들은 그 시간의 대부분을 I/O 요청을 보내고 기다리는 데 사용한다. 짧은 기간 동안만 실행가능하게 되는데, 왜냐하면 다른 I/O 요청에 의해 결국 또다시 대기 상태로 되기 때문이다. `(예 : 디스크, 키보드)`

- **프로세서 중심 프로세스**들은 코드를 실행하는 데 대부분의 시간을 보낸다. 보통 선점되기 전까지 계속 실행되는데, 왜냐하면 I/O 요청 등으로 중단되지 않기 때문이다.

- 스케줄러 정책은 항상 **대립되는 두 가지 목표**를 갖는다. ① **`빠른 응답 시간(낮은 지연)`** 과 ② **`높은 프로세스 처리량`** 을 만족시켜야 한다. 이러한 요구조건을 만족시기 위해 스케줄러는 다른 프로세스와의 공정성을 고려하여 실행시키기 가장 알맞은 프로세스를 결정한다.

- **리눅스**는 좋은 응답성을 제공하기 위해 프로세스 응답 시간에 최적화 되었기 때문에, 프로세서 중심보다 **I/O 중심 프로세스를 선호**한다.

### 프로세스 우선순위

스케줄링 알고리즘 중 가장 흔한 형태가 우선순위에 기반을 둔 알고리즘으로 리눅스 커널은 두 가지의 우선순위를 구현하고 있다.

첫 번째는 nice값으로 -20에서 +19까지의 값을 갖는다.(기본값 0) 큰 nice값은 낮은 우선순위를 의미한다. 따라서 낮은 nice값을 갖는 프로세스들은 높은 nice값을 갖는 프로세스보다 먼저 실행된다. nice 값은 각 프로세스가 얼마나 타임슬라이스를 할당받는가를 결정하는 데도 사용된다.

 nice값이 -20인 프로세스는 최대 타임슬라이스를 할당받고, 19인 프로세스는 가장 작은 타임슬라이스를 할당받는다.
 
두 번째는 실시간 우선순위로서, 0에서 99까지의 값을 갖는다. 또 모든 실시간 프로세스는 일반 프로세스보다 높은 우선순위를 부여받는다.


### 타임슬라이스

프로세스가 선점 다중 작업 시스템에서 실행할 수 있는 시간대를 `타임 슬라이스(time slice)` 또는 `퀀텀(quantum)` 이라고 한다.

- 타임슬라이스가 너무 길면 시스템의 InterActive한 성능을 떨어뜨려 프로세스가 동시에 수행되는 것처럼 느껴지지 않을 것이며, 너무 짧으면 프로세스간의 스위칭이 자주 일어나 자원낭비의 비효율성이 발생한다.

- 높은 우선순위를 갖는 작업이 좀더 길게, 자주 수행되게 되는데 프로세스가 모든 타임슬라이스를 반드시 한번에 소비해야 하는 것은 아니다.

#### context-switching

- 프로세스의 context-switching 비용보다 스레드의 context-switching 비용이 적다.

    - 프로세스의 context-switching을 할 경우, 환경까지 바꿔야하므로 비용이 많이 든다.


### 'O(1)' 스케쥴러, 'CFS' 스케쥴러

> `O(1)` 스케쥴러

- 절대값을 기준으로 등급을 줄때 문제점이 있다.

> `CFS(Completely Fair Scheduler)` 스케쥴러

- 값이 상대적이다.

- O(1) 스케쥴러에 있던 **Starving** 문제점을 해결

 - 주어진 시간을 가장 적게 소모한 것이


### 'CISC' & 'RISC'


### '마이크로 커널' & '모놀리딕 커널'

> [타넨바움 - 토발즈 논쟁](https://zetawiki.com/wiki/Tanenbaum%E2%80%93Torvalds_%EB%85%BC%EC%9F%81)

```
타넨바움 - 미닉스(마이크로 커널)
토발즈 - 리눅스(모놀리딕 커널)
```

- 마이크로 커널

    - 윈도 OS

    - 데이비드 커틀러의 마이크로소프트 윈도 NT


- 모놀리딕 커널 
 
    - 새로운 기능을 추가하면 새로 컴파일



---

## 참고

Concurrency, Parallelism 차이 : https://12bme.tistory.com/184

리눅스커널 - 프로세스 스케줄링 : http://dblab.co.kr/entry
